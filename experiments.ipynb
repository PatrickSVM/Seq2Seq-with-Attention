{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Machine Translation with Attention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets as lists\n",
    "with open(\"./data/europarl-v7.de-en.de\") as file:\n",
    "    ger = [line.rstrip() for line in file]\n",
    "with open(\"./data/europarl-v7.de-en.en\") as file:\n",
    "    eng = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920209\n"
     ]
    }
   ],
   "source": [
    "print(len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920209"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of english words: 47882343\n",
      "Number of german words: 44614285\n"
     ]
    }
   ],
   "source": [
    "words = 0\n",
    "for sent in eng:\n",
    "    words += len(sent.split())\n",
    "print(f\"Number of english words: {words}\")\n",
    "\n",
    "words = 0\n",
    "for sent in ger:\n",
    "    words += len(sent.split())\n",
    "print(f\"Number of german words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization - use spacy\n",
    "import spacy\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_ger(text):\n",
    "    \"\"\"\n",
    "    Take german sentence and tokenize it using spacy. \n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    \"\"\"\n",
    "    Take english sentence and tokenize it using spacy. \n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "src_field = Field(init_token = '<sos>', \n",
    "            eos_token = '<eos>',\n",
    "            pad_token='<pad>', \n",
    "            unk_token='<unk>',\n",
    "            lower = True, \n",
    "            include_lengths = True,\n",
    "            sequential=True,\n",
    "            batch_first=True)\n",
    "\n",
    "trg_field = Field(init_token = '<sos>', \n",
    "            eos_token = '<eos>',\n",
    "            pad_token='<pad>', \n",
    "            unk_token='<unk>',\n",
    "            lower = True, \n",
    "            include_lengths = True,\n",
    "            sequential=True,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "ger_token = [tokenize_ger(sent) for sent in ger]\n",
    "eng_token = [tokenize_eng(sent) for sent in eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab size 32K\n",
    "# https://jlibovicky.github.io/2021/07/24/MT-Weekly-The-Wisdom-of-the-WMT-Crowd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 32000\n",
    "src_field.build_vocab(ger_token, min_freq=2, max_size=max_vocab_size)\n",
    "trg_field.build_vocab(eng_token,  min_freq=2, max_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397884\n",
      "32004\n",
      "32004\n"
     ]
    }
   ],
   "source": [
    "# Frequency hodls all frequencies\n",
    "print(len(SRC.vocab.freqs))\n",
    "\n",
    "# ITOS/\n",
    "print(len(SRC.vocab.stoi))\n",
    "print(len(SRC.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TextDtaatset(Dataset):\n",
    "\n",
    "  def __init__(self, data):\n",
    "    self.text = data\n",
    "    \n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.text)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    return self.text[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_dataset = TextDtaatset(data=ger_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define iterator\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "iterator = BucketIterator.splits(datasets=ger_dataset, batch_size=2, sort_key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "with open('./data/train_de') as src, open('./data/train_en') as tgt:\n",
    "    with open('./data/train.csv','w') as file:\n",
    "        for src_sentence, tgt_sentence in zip(src, tgt):\n",
    "            line = f'{src_sentence.rstrip()} , {tgt_sentence.rstrip()}'\n",
    "            file.write(line)\n",
    "            file.write('\\n')\n",
    "\n",
    "with open('./data/val_de') as src, open('./data/val_en') as tgt:\n",
    "    with open('./data/val.csv','w') as file:\n",
    "        for src_sentence, tgt_sentence in zip(src, tgt):\n",
    "            line = f'{src_sentence.rstrip()} , {tgt_sentence.rstrip()}'\n",
    "            file.write(line)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_obj, valid_obj) = TabularDataset.splits(\n",
    "  path=\"\",\n",
    "  train='./data/val.csv',\n",
    "  validation='./data/val.csv',\n",
    "  format='csv',\n",
    "  fields=[('src',src_field ), ('trg', trg_field)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseq2seq_attention\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuild_dataloaders\u001b[39;00m \u001b[39mimport\u001b[39;00m build_vocab\n\u001b[0;32m----> 2\u001b[0m build_vocab(train_set\u001b[39m=\u001b[39;49mtrain_obj)\n",
      "File \u001b[0;32m~/Documents/Python_projects/Seq2Seq-with-Attention/seq2seq_attention/build_dataloaders.py:79\u001b[0m, in \u001b[0;36mbuild_vocab\u001b[0;34m(train_set, min_freq, max_vocab_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mglobal\u001b[39;00m src_field\n\u001b[1;32m     78\u001b[0m \u001b[39mglobal\u001b[39;00m trg_field \n\u001b[0;32m---> 79\u001b[0m src_field\u001b[39m.\u001b[39mbuild_vocab(train_set, min_freq\u001b[39m=\u001b[39mmin_freq, max_size\u001b[39m=\u001b[39mmax_vocab_size)\n\u001b[1;32m     80\u001b[0m trg_field\u001b[39m.\u001b[39mbuild_vocab(train_set,  min_freq\u001b[39m=\u001b[39mmin_freq, max_size\u001b[39m=\u001b[39mmax_vocab_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src_field' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from seq2seq_attention.build_dataloaders import build_vocab\n",
    "build_vocab(train_set=train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'build_vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[247], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src_field \u001b[39m=\u001b[39m src_field\u001b[39m.\u001b[39;49mbuild_vocab(train_obj, min_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_size\u001b[39m=\u001b[39mmax_vocab_size)\n\u001b[1;32m      2\u001b[0m trg_field \u001b[39m=\u001b[39m trg_field\u001b[39m.\u001b[39mbuild_vocab(train_obj,  min_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_size\u001b[39m=\u001b[39mmax_vocab_size)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'build_vocab'"
     ]
    }
   ],
   "source": [
    "src_field.build_vocab(train_obj, min_freq=1, max_size=max_vocab_size)\n",
    "trg_field.build_vocab(train_obj,  min_freq=1, max_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(\n",
    "  dataset=train_obj,\n",
    "  batch_size = 2,\n",
    "  sort_key=lambda x: len(x.src),\n",
    "  shuffle=True,\n",
    "  device=\"cpu\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 2,  4,  6,  3,  1,  1],\n",
      "        [ 2, 14,  8,  7, 10,  3]]), tensor([4, 6]))\n",
      "(tensor([[ 2,  5,  9,  3,  1],\n",
      "        [ 2,  7,  4, 10,  3]]), tensor([4, 5]))\n"
     ]
    }
   ],
   "source": [
    "example=next(iter(train_iter))\n",
    "src = example.src\n",
    "trg = example.trg\n",
    "print(src)\n",
    "print(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>\n",
      "bestens\n",
      "danke\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "\n",
      "<sos>\n",
      "fine\n",
      "thanks\n",
      "<eos>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "# itos is list of token strings with their idx \n",
    "for i in src[0][0]:\n",
    "    print(src_field.vocab.itos[i])\n",
    "print()\n",
    "for i in trg[0][0]:\n",
    "    print(trg_field.vocab.itos[i])\n",
    "\n",
    "# The second element in the tuple is the real length that we pass to the packed_seq!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional GRU\n",
    "import torch.nn as nn\n",
    "emb = nn.Embedding(num_embeddings=5, embedding_dim=10)\n",
    "gru = nn.GRU(input_size=10, hidden_size=4, num_layers=1,  bidirectional = True, batch_first=True, bias=True,)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input = torch.tensor([[1,2], [1,2], [0,1]])\n",
    "input_len = torch.tensor([2,2,1])\n",
    "embed = emb(input)\n",
    "packed_embedded_src = nn.utils.rnn.pack_padded_sequence(\n",
    "                embed, lengths=input_len, batch_first=True, enforce_sorted=True\n",
    "            )\n",
    "all, last = gru(packed_embedded_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenaeted version of the hdiden states \n",
    "# data: (num_real_seq, 2*hidden_dim)\n",
    "all.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Bidir, batch, hidden_dim) two hidden states for all directions, \n",
    "last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all back \n",
    "out, _ =nn.utils.rnn.pad_packed_sequence(\n",
    "                all,batch_first=True, \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 8])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiden_final = torch.cat([last[0,:,:], last[1,:,:]], dim=1)\n",
    "hiden_final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 8])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets concat each one with the resbectve \n",
    "hidden.unsqueeze(1).repeat(1, src_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 16])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([out, hiden_final.unsqueeze(1).repeat(1,2,1)], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 8])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiden_final.unsqueeze(1).repeat(1,6,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_len = torch.tensor([1,2,3,4])\n",
    "src_len_padded=6\n",
    "\n",
    "mask = torch.zeros((4,src_len_padded), dtype=torch.bool)\n",
    "mask[[1,2,3,3,3,3],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  2,  3],\n",
       "        [10, 10,  2]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3], [1,1,2]])\n",
    "\n",
    "a[torch.tensor([[1,2,3], [1,1,2]])==1] = 10\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3], [1,1,2]])\n",
    "b = torch.tensor([[1,3], [1,2]])\n",
    "torch.cat([a,b], dim=1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3], [1,1,2]])\n",
    "b = torch.tensor([[1], [1]])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "torch.cat([a,b], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full(size=(2,1), fill_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.2931e-05)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "y = torch.tensor([[1,1,1], [1,1,1]], dtype=torch.long)\n",
    "out = torch.tensor([[[0,10,-1, -4], [0,10,-1,-4], [0,10,-1,-4]], [[0,10,-1,-4],[0,10,-1,-4],[0,10,-1,-4]]],dtype=torch.float32)\n",
    "out=out.permute(0,2,1)\n",
    "print(y.shape)\n",
    "print(out.shape)\n",
    "loss(out, y)\n",
    "\n",
    "# Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.0001)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "y = torch.tensor([[1,1,1], [1,1,1]], dtype=torch.long)\n",
    "out = torch.tensor([[[100,10,-1, -4], [0,10,-1,-4], [0,10,-1,-4]], [[0,10,-1,-4],[0,10,-1,-4],[0,10,-1,-4]]],dtype=torch.float32)\n",
    "out=out.permute(0,2,1)\n",
    "loss(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.0000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "y = torch.tensor([[1,1,1], [1,1,1]], dtype=torch.long)\n",
    "out = torch.tensor([[[100,10,-1, -4], [100,10,-1,-4], [0,10,-1,-4]], [[0,10,-1,-4],[0,10,-1,-4],[0,10,-1,-4]]],dtype=torch.float32)\n",
    "out=out.permute(0,2,1)\n",
    "loss(out, y)\n",
    "\n",
    " # Gets summed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted hidden states\n",
    "all_hidden = torch.tensor([[[1,2,0], [3,4,0]], \n",
    "                           [[1,2,0], [3,4,0]], \n",
    "                           [[1,2,0], [3,4,0]], \n",
    "                           [[1,2,0], [3,4,0]]])\n",
    "weights = torch.tensor([[0,1], [1,0], [0,0], [1,1]])\n",
    "\n",
    "def weighted_sum(H, K):\n",
    "    weighted = (H * K.unsqueeze(2)).sum(dim=1)\n",
    "    return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(all_hidden.shape)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum(all_hidden, weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 0],\n",
       "        [1, 2, 0],\n",
       "        [0, 0, 0],\n",
       "        [4, 6, 0]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum(all_hidden, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb(torch.tensor([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"experiment_4\"\n",
    "\n",
    "lr = 5e-4\n",
    "batch_size = 80\n",
    "epochs = 15\n",
    "max_vocab_size = 20000\n",
    "min_freq = 2\n",
    "enc_emb_dim = 256\n",
    "hidden_dim_enc = 512\n",
    "hidden_dim_dec = 512\n",
    "num_layers_enc = 1\n",
    "num_layers_dec = 1\n",
    "emb_dim_trg = 256\n",
    "device = \"cuda\"\n",
    "teacher_forcing = 0.5\n",
    "\n",
    "from seq2seq_attention.build_dataloaders import build_fields, get_datasets, build_vocab\n",
    "\n",
    "src, trg = build_fields()\n",
    "src_field, trg_field = build_fields()\n",
    "train_set, val_set, test_set = get_datasets(train_path=\"./data/processed/train_mini.csv\", \n",
    "                                            val_path=\"./data/processed/train_mini.csv\", \n",
    "                                            test_path=\"./data/processed/train_mini.csv\", \n",
    "                                            src_field=src_field, \n",
    "                                            trg_field=trg_field)\n",
    "build_vocab(src_field=src_field, trg_field=trg_field, train_set=train_set, min_freq=min_freq, max_vocab_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq_Architecture_with_Att:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([19470, 256]) from checkpoint, the shape in current model is torch.Size([10894, 256]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([12226, 256]) from checkpoint, the shape in current model is torch.Size([8077, 256]).\n\tsize mismatch for decoder.output_layer.weight: copying a param with shape torch.Size([12226, 1792]) from checkpoint, the shape in current model is torch.Size([8077, 1792]).\n\tsize mismatch for decoder.output_layer.bias: copying a param with shape torch.Size([12226]) from checkpoint, the shape in current model is torch.Size([8077]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m\n\u001b[1;32m      5\u001b[0m best_model_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m./experiments/Experiment_4/best_model.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m Seq2Seq_With_Attention(\n\u001b[1;32m      8\u001b[0m         lr\u001b[39m=\u001b[39mlr,\n\u001b[1;32m      9\u001b[0m         enc_vocab_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(src_field\u001b[39m.\u001b[39mvocab),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         seq_beginning_token_idx\u001b[39m=\u001b[39mtrg_field\u001b[39m.\u001b[39minit_token,\n\u001b[1;32m     21\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m model\u001b[39m.\u001b[39;49mseq2seq\u001b[39m.\u001b[39;49mload_state_dict(best_model_vals[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m/local/data1/pathi619/envs/Seq2Seq/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq_Architecture_with_Att:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([19470, 256]) from checkpoint, the shape in current model is torch.Size([10894, 256]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([12226, 256]) from checkpoint, the shape in current model is torch.Size([8077, 256]).\n\tsize mismatch for decoder.output_layer.weight: copying a param with shape torch.Size([12226, 1792]) from checkpoint, the shape in current model is torch.Size([8077, 1792]).\n\tsize mismatch for decoder.output_layer.bias: copying a param with shape torch.Size([12226]) from checkpoint, the shape in current model is torch.Size([8077])."
     ]
    }
   ],
   "source": [
    "from seq2seq_attention.model import Seq2Seq_Architecture_with_Att, Seq2Seq_With_Attention, Encoder, Decoder, Attention\n",
    "import torch \n",
    "\n",
    "# Init from file\n",
    "best_model_vals = torch.load(\"./experiments/Experiment_4/best_model.pt\")\n",
    "\n",
    "model = Seq2Seq_With_Attention(\n",
    "        lr=lr,\n",
    "        enc_vocab_size=len(src_field.vocab),\n",
    "        vocab_size_trg=len(trg_field.vocab),\n",
    "        enc_emb_dim=enc_emb_dim,\n",
    "        hidden_dim_enc=hidden_dim_enc,\n",
    "        hidden_dim_dec=hidden_dim_dec,\n",
    "        padding_idx=src_field.vocab.stoi[\"<pad>\"],\n",
    "        num_layers_enc=num_layers_enc,\n",
    "        num_layers_dec=num_layers_dec,\n",
    "        emb_dim_trg=emb_dim_trg,\n",
    "        trg_pad_idx=trg_field.vocab.stoi[\"<pad>\"],\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        min_freq=min_freq,\n",
    "        device=device,\n",
    "        seq_beginning_token_idx=trg_field.init_token,\n",
    "    )\n",
    "\n",
    "\n",
    "model.seq2seq.load_state_dict(best_model_vals[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seq2Seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6471f541d6a3d6af3090569c48630ed02e63e077dabe047b0999f254fcb2697f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
