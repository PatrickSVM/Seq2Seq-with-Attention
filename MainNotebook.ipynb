{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Machine Translation with Attention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "Dataset link: https://www.statmt.org/wmt13/training-parallel-europarl-v7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920209\n",
      "1920209\n"
     ]
    }
   ],
   "source": [
    "# Check the size of both datasets\n",
    "with open(\"./data/unprocessed/europarl-v7.de-en.de\") as file:\n",
    "    ger = [line.rstrip() for line in file]\n",
    "with open(\"./data/unprocessed/europarl-v7.de-en.en\") as file:\n",
    "    eng = [line.rstrip() for line in file]\n",
    "\n",
    "print(len(eng))\n",
    "print(len(ger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy data\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully created.\n",
      "11289 lines were removed.\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_attention.preprocess import get_parallel_csv\n",
    "\n",
    "# Take \">\" as seperator since it is not included in the text - unique to seperate eng-ger pairs. \n",
    "# Remove any \">\" from text pairs.\n",
    "get_parallel_csv(path_1=\"./data/unprocessed/europarl-v7.de-en.de\", path_2=\"./data/unprocessed/europarl-v7.de-en.en\", new_file_path=\"./data/processed/en_ger_full.csv\", delimiter=\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully created.\n",
      "824619 sentence-pairs were removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove sentences with lower number of words\n",
    "from seq2seq_attention.preprocess import remove_sentences\n",
    "remove_sentences(data_dir=\"./data/processed/en_ger_full.csv\", min_length=4, max_length=30, delimiter=\">\", new_file_path=\"./data/processed/en_ger_full_removed_sent_len.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files successfully created.\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_attention.preprocess import train_test_split\n",
    "train_test_split(file_path=\"./data/processed/en_ger_full_removed_sent_len.csv\", sep=\">\", random_seed=118, dir=\"./data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check files\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/processed/train.csv\", header=None, sep=\">\", names=[\"ger\", \"eng\"])\n",
    "val = pd.read_csv(\"./data/processed/val.csv\", header=None, sep=\">\", names=[\"ger\", \"eng\"])\n",
    "test = pd.read_csv(\"./data/processed/test.csv\", header=None,sep=\">\", names=[\"ger\", \"eng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 867441, Val: 108430, Test: 108430\n",
      "Total: 1084301\n",
      "Total + Removed: 1920209\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train)\n",
    "val_len = len(val)\n",
    "test_len = len(test)\n",
    "print(f\"Train: {train_len}, Val: {val_len}, Test: {test_len}\")\n",
    "print(f\"Total: {train_len+val_len+test_len}\")\n",
    "print(f\"Total + Removed: {train_len+val_len+test_len+11289+824619}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ger</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indessen ist weder bei Bulgarien noch bei Rumä...</td>\n",
       "      <td>Neither Bulgaria nor Romania’s accession proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seit Amsterdam stehen drei Begriffe im Mittelp...</td>\n",
       "      <td>Since Amsterdam, three terms have taken centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Um die Kyoto-Ziele zu erfüllen und die Umwelt ...</td>\n",
       "      <td>In order to meet the Kyoto objectives and to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Das irische Volk hat die spezifische Version d...</td>\n",
       "      <td>The Irish people rejected the particular vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es gab eindeutige Hinweise auf organisierte An...</td>\n",
       "      <td>There were clear signs of organised attacks o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ger  \\\n",
       "0  Indessen ist weder bei Bulgarien noch bei Rumä...   \n",
       "1  Seit Amsterdam stehen drei Begriffe im Mittelp...   \n",
       "2  Um die Kyoto-Ziele zu erfüllen und die Umwelt ...   \n",
       "3  Das irische Volk hat die spezifische Version d...   \n",
       "4  Es gab eindeutige Hinweise auf organisierte An...   \n",
       "\n",
       "                                                 eng  \n",
       "0   Neither Bulgaria nor Romania’s accession proc...  \n",
       "1   Since Amsterdam, three terms have taken centr...  \n",
       "2   In order to meet the Kyoto objectives and to ...  \n",
       "3   The Irish people rejected the particular vers...  \n",
       "4   There were clear signs of organised attacks o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ger</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wir können die Änderungsanträge 49 und 50 nich...</td>\n",
       "      <td>We cannot accept Amendments Nos 49 and 50, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daher schlage ich vor, dass wir uns unter hohe...</td>\n",
       "      <td>That is why, while keenly appreciating the ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deshalb sollten wir versuchen, diesem anderen ...</td>\n",
       "      <td>It is to this other Iran, then, that we shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es besteht kein Mangel an Kreativität, was den...</td>\n",
       "      <td>There is no lack of creativity when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich bitte dringend darum, den Themen mehr Aufm...</td>\n",
       "      <td>I would urge that more attention be paid to i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ger  \\\n",
       "0  Wir können die Änderungsanträge 49 und 50 nich...   \n",
       "1  Daher schlage ich vor, dass wir uns unter hohe...   \n",
       "2  Deshalb sollten wir versuchen, diesem anderen ...   \n",
       "3  Es besteht kein Mangel an Kreativität, was den...   \n",
       "4  Ich bitte dringend darum, den Themen mehr Aufm...   \n",
       "\n",
       "                                                 eng  \n",
       "0   We cannot accept Amendments Nos 49 and 50, wh...  \n",
       "1   That is why, while keenly appreciating the ri...  \n",
       "2   It is to this other Iran, then, that we shoul...  \n",
       "3   There is no lack of creativity when it comes ...  \n",
       "4   I would urge that more attention be paid to i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ger</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sie haben Regulierungsinstrumente für die Prod...</td>\n",
       "      <td>They have destroyed regulatory instruments fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keine andere Meinung zählt.</td>\n",
       "      <td>Nobody else has a say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deshalb müssen wir dagegen protestieren, dass ...</td>\n",
       "      <td>That is why we must protest against the fact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Aussprache ist hiermit geschlossen.</td>\n",
       "      <td>That concludes the debate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wie meine Vorredner und Vorrednerinnen, Herr K...</td>\n",
       "      <td>Like the previous speakers, Commissioner, I t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ger  \\\n",
       "0  Sie haben Regulierungsinstrumente für die Prod...   \n",
       "1                       Keine andere Meinung zählt.    \n",
       "2  Deshalb müssen wir dagegen protestieren, dass ...   \n",
       "3           Die Aussprache ist hiermit geschlossen.    \n",
       "4  Wie meine Vorredner und Vorrednerinnen, Herr K...   \n",
       "\n",
       "                                                 eng  \n",
       "0   They have destroyed regulatory instruments fo...  \n",
       "1                             Nobody else has a say.  \n",
       "2   That is why we must protest against the fact ...  \n",
       "3                         That concludes the debate.  \n",
       "4   Like the previous speakers, Commissioner, I t...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_attention.build_dataloaders import build_fields, build_bucket_iterator, get_datasets, build_vocab\n",
    "BATCH_SIZE = 100\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "src_field, trg_field = build_fields()\n",
    "train_set, val_set, test_set = get_datasets(train_path=\"./data/processed/train.csv\", \n",
    "                                            val_path=\"./data/processed/val.csv\", \n",
    "                                            test_path=\"./data/processed/test.csv\", \n",
    "                                            src_field=src_field, \n",
    "                                            trg_field=trg_field)\n",
    "build_vocab(src_field=src_field, trg_field=trg_field, train_set=train_set, min_freq=2, max_vocab_size=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check vocabulary \n",
    "len(src_field.vocab)\n",
    "src_field.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7fb1d02f3b20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_field.vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = build_bucket_iterator(dataset=train_set, batch_size=BATCH_SIZE, device=DEVICE)\n",
    "val_loader = build_bucket_iterator(dataset=val_set, batch_size=BATCH_SIZE, device=DEVICE)\n",
    "test_loader = build_bucket_iterator(dataset=test_set, batch_size=BATCH_SIZE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sample batch\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 6]) torch.Size([100])\n",
      "torch.Size([10]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "example = next(iterator)\n",
    "src_batch = example.src\n",
    "trg_batch = example.trg\n",
    "print(src_batch[0].shape, src_batch[1].shape)\n",
    "print(trg_batch[0].shape, trg_batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "print(src_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   2,   17,   13, 3232,    6,    3,    1,    1,    1,    1])\n"
     ]
    }
   ],
   "source": [
    "print(trg_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <sos> gibt es einwände ? <eos>\n",
      " <sos> are there any comments ? <eos> <pad> <pad> <pad>\n",
      "\n",
      " <sos> das ist absurd . <eos>\n",
      " <sos> this is absurd . <eos> <pad> <pad> <pad> <pad>\n",
      "\n",
      " <sos> - vor der abstimmung <eos>\n",
      " <sos> - before the vote : <eos> <pad> <pad> <pad>\n",
      "\n",
      " <sos> <unk> ( fortsetzung ) <eos>\n",
      " <sos> alpine transit ( continuation ) <eos> <pad> <pad> <pad>\n",
      "\n",
      " <sos> das ist bedauernswert . <eos>\n",
      " <sos> that is regrettable . <eos> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# itos is list of token strings with their idx \n",
    "for j in range(5):\n",
    "    src = \"\"\n",
    "    for i in src_batch[0][j]:\n",
    "       src = \" \".join([src,  src_field.vocab.itos[i]])\n",
    "    print(src)\n",
    "    trg = \"\"\n",
    "    for i in trg_batch[j]:\n",
    "        trg = \" \".join([trg, trg_field.vocab.itos[i]])\n",
    "    print(trg)\n",
    "    print()\n",
    "# The second element in the tuple is the real length that we pass to the packed_seq!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Create small trainig set to test computaitons \n",
    "with open(\"./data/processed/train.csv\", \"r\") as file:\n",
    "        with open(\"./data/processed/train_mini.csv\", \"w\") as new_file:\n",
    "            i = 0\n",
    "            for line in file:\n",
    "                if i < 1000:\n",
    "                    new_file.write(line)\n",
    "                    \n",
    "                i+=1\n",
    "print(\"File successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seq2Seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6471f541d6a3d6af3090569c48630ed02e63e077dabe047b0999f254fcb2697f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
